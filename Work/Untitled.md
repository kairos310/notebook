### Pipeline

Preprocessing, alignment, and quality control of RIP-seq/Total RNA-seq experiments were performed
using `nf-core/rna-seq` pipeline:

```bash
apt-get install default-jre
apt-get install graphviz

cd pipeline
export NXF_VER=21.10.0
curl -s https://get.nextflow.io | bash
./nextflow -bg run nf-core/rnaseq -resume -profile docker -revision 3.4 --input=design.csv --genome=GRCm38
```

To start a pipeline from scratch, one needs to download raw fq.gz reads from the SRA(PRJNA767097, PRJNA767108), place
them in the `pipeline/fq.gz` folder, and modify the design document accordingly.

We also additionally filtered the aligned BAM files with the following command:

```bash
cd pipeline/results/star_salmon
mkdir final-bams
for file in *.bam
do
    samtools view -@ $(nproc) -F 2820 -b $file > final-bams/$file
done
```

### Analysis

All software dependencies are described in the Dockerfile. To reproduce the environment use the following commands:

Then run any **Python** script in the `scripts` folder. Additional notes for some steps are listed below.

#### DE genes

We used DESeq2 to determine genes enriched in Z22 RIP-seq over Total RNA-seq. One can run the whole analysis
using `DEG/run-DE.py` script.

Note, the analysis is based on the Salmon per-gene(transcript, in fact) quantification results. They are stored directly
in the repository and correspond to `pipeline/results/star_salmon/SAMPLE/quant.sf` files generated by the pipeline.

To augment our set of ISGs with early IFN-genes, we used RNA-seq data from `GSE118926`. The experiment was processed by
the same pipeline; Salmon counts are provided in the `analysis/resources/GSE118926` folder.

#### Alu editing index (AEI)

To compute the AEI index we used the following commands:

```bash
# Go to directory containing final-bams folder with filtered BAM files
cd pipeline/results/star_salmon/final-bams
# Reheader each BAM file (1->chr1)
for file in *.bam
do
    newfile=${file/.bam/_chr.bam}
    samtools view -H $file | sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | samtools reheader - $file > $newfile
    rm -rf $file
    mv $newfile $file
done
cd ...
# build docker image
sudo docker build -t rnaedits https://raw.githubusercontent.com/a2iEditing/RNAEditingIndexer/master/Dockerfile
# run the container
sudo docker run -v $(pwd):/data --rm -it rnaedits bash
# launch the pipeline
RNAEditingIndex -d /data/final-bams -l /data/logs -o /data/output -os /data/editing-summary -f .bam --genome mm10 --ts $(nproc)
```

The output file located in the `summary` folder was hand-formatted and then attached as a supplement table to the GEO
submission (GSE184964).

#### Editing index for other repeats

We also calculated the index for other repeat families:

```bash
cd analysis/results/editing-index
mkdir values

sudo docker run -v $(pwd):/data --rm -it ranedits bash

for repeat in LINE LTR Low_complexity RC RNA Satellite Simple_repeat scRNA snRNA srpRNA SINE
do
    RNAEditingIndex --genome mm10 --ts $(nproc) --per_region_output --per_sample_output \ 
                    -rb /data/intervals/$repeat.bed -d /data/bam -l /data/logs \ 
                    -o /data/output -os /data/summary-$repeat -f .bam 
    rm -rf logs output
    mv /data/summary-$repeat values/$repeat
done
```

#### Mapping fragments to exons/introns/intergenic regions

To calculate a summary table showing the percentage of fragments falling into exons / introns / intergenic regions, it
is necessary to sort and place the BAM files in the `resources / BAM` folder:

```bash
cd pipeline/results/star_salmon/final-bams
for file in *.bam
do
    newfile=../../../../analysis/resources/BAM/${file/markdup.sorted.bam/.namesorted.bam}
    samtools sort -@ $(nproc) -n -o $newfile $file
done
```

Then run scripts in the `Reads distribution` folder.

----

#### Errors 

```
E: Version '1.1.1f-1ubuntu2.4' for 'libssl-dev' was not found
E: Version '7.68.0-1ubuntu2.5' for 'curl' was not found
E: Version '7.68.0-1ubuntu2.5' for 'libcurl4-openssl-dev' was not found
E: Version '2.9.10+dfsg-5ubuntu0.20.04.1' for 'libxml2-dev' was not found
```
# Chip Seq
In total, 5 ChIP-seq experiments were analyzed with the following antibodies: **Z22**(curaxin 14h), **IgG**(curaxin 14h/0h), and **FLAG**(curaxin 14h/0h). Each experiment had two technical replicates.

Here, curaxin 0h refers to untreated cells, **Z22** is an antibody for Z-DNA, **IgG** is a nonspecific antibody (control), and **FLAG** is an antibody to FLAG-tagged ZBP1 protein. 

### Pipeline
Initial processing was performed via the Snakemake pipeline(`pipeline` folder):
```bash
cd pipeline
sudo docker build -t chipseq:latest docker/
sudo docker run --rm -it -v $(pwd):/project --name chipseq-container chipseq:latest
snakemake --cores $(nproc) --configfile config/config.yaml -d . --snakefile workflow/Snakefile  all

```


```
docker run -it --rm -u 0 mambaorg/micromamba:jammy /bin/bash

micromamba activate && micromamba install python=3.7 jupyter -c -y conda-forge
micromamba config append channels conda-forge
micromamba config append channels bioconda
micromamba install -y -c bioconda \
```

Before running the pipeline, make sure to place raw fq.gz files in `pipeline/results/pe-{SAMPLE NAME}/fq.gz` folders. Refer to the `pipeline/config/config.yaml` for a list of samples used in the research (fq.gz files can be downloaded from the SRA: SRP339170).

Once the pipeline finishes, called peaks, fold enrichment tracks and basic QC metrics will be available in the `pipeline/results` folder.

### Analysis
#### Resources
The `analysis` folder contains scripts to reproduce chip-seq relevant plots and supplements. These scripts depends on the pipeline results, which can be linked like this:
```bash
# genome
ln -f $(pwd)/pipeline/resources/mm10/genome.fa $(pwd)/analysis/resources/genome.fa
# fold enrichment
cp -R pipeline/results/signal/ analysis/resources/signal
# peaks
cp -R pipeline/results/peaks/ analysis/resources/peaks
```
There are additional external data (RepeatMasker annotation, ENCODE blacklist, L1Base) stored directly in the repository. To avoid running the entire pipeline, one can use signal and peak files from the GEO submission.

Some scripts require a compiled [zhunt](https://github.com/Ho-Lab-Colostate/zhunt) program, which can be built with GCC: `gcc analysis/resources/zhunt2.c -lm -o analysis/resources/zhunt2`.
#### Reproducibility
The first step to reproduce the analysis is to restore the environment described in the docker file:
```bash
cd analysis
sudo docker build -t chipseq-analysis:latest docker/
#sudo docker run --rm -it -v $(pwd):/project --name chipseq-analysis-container chipseq-analysis:latest
sudo docker run --rm -itd --name chipseq-analysis-container chipseq-analysis:latest
sudo docker cp ../pipeline/. chipseq-analysis-container:/project

#sudo docker run -v $(pwd):/project --rm -itd --name ubuntu:20.04 chipseq:latest
#sudo docker cp ../pipeline/. chipseq-analysis:/project
sudo docker attach chipseq-analysis-container

```
Then run any **Python** script in the `scripts` folder, for example: `python3 scripts/mm10-coverage-by-repeats`. 
